#### 事务

##### 四大特性

Atomic - 原子性

> 事务是一个不可分割的操作，要么全部执行，要么都不执行

Consistency - 一致性

> 事务前后，数据库的完整性约束没有被破坏

Isolation - 隔离性

> 数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致

Durability - 持久性

> 事务结束之后，其对数据库中数据所做的修改是永久性的

##### 多事务并发可能出现的问题

- 更新丢失：当两个事务同时更新一条数据时，A事务可能将B事务还未提交的数据再次更新，导致两个事务都更新失败，丢失更新信息
- 脏读：A事务读取到B事务更新但未提交的数据，但B事务回滚了，A事务读到的就是脏数据
- 不可重复读：在同一事务中对一行数据的两次读取得到不同的结果
- 幻读：事务在执行过程中进行两次查询，后一次查询的结果出现了前一次查询中没有出现过或者缺少的结果，如在A事务两次读取同一条记录中间，B事务对该记录进行了修改，导致A事务第二次读取读到了不一样的结果

##### 事务隔离级别

- 读未提交：事务A可以读到事务B修改但还未提交的数据，但不能修改它
- 读提交：事务B的修改（写操作）只有在提交之后才可以被事务A看到
- 可重复读：一个事务执行过程中看到的数据总是和事务开始时看到的数据是一致的，**MySQL默认隔离级别**
- 串行化：对读写操作都加锁

##### 实现原理

- 通过创建视图使得访问的时候以视图的逻辑结果为主
- 读未提交：直接返回记录上的最新值，没有视图概念
- 读提交：视图是在SQL开始执行时创建
- 可重复读：视图在事务开启时创建，事务执行过程中都使用该视图
- 串行化：直接用加锁的方式避免并行访问

##### 具体实现

每条记录在更新的时候都会记录一条回滚操作，同一条记录在系统中存在多个版本，称为**多版本并发控制MVCC**。

InnoDB中每个事务都有唯一的事务ID：transaction_id，它是在事务开始时向InnoDB的事务系统申请的，严格递增。每次事务更新数据时都会生成一个新的数据版本，并将自己的transaction_id赋值过去，记为row_trx_id。同时旧的数据版本保留，也就是说，表中的一行记录可能有多个版本，每个版本有自己的row_trx_id

![](<https://user-images.githubusercontent.com/34979747/69492288-9cd43100-0edb-11ea-94f2-7d00df7bf796.png>)

按照可重复读的级别，一个事务启动时只能看到它之前生成的数据版本，如果一个数据版本是它之后生成的，则必须找到其上一个版本的数据。所以，InnoDB在事务启动时为其创建了一个数组，用于保存当前事务启动时所有活跃的事务id，就是启动了还未提交的所有事务。数组中事务ID最小值称为“低水位”，目前已创建的事务的ID的最大值加1记为“高水位”。根据这个数组，将数据的row_trx_id与其比对即可确定可见与否。**InnoDB利用所有数据都有多个版本的特性，实现秒级创建快照**。

##### 事务启动方式

- 显式启动事务：begin / start transaction，commit，rollback
- set autocommit = 0，该命令会把这个线程的自动提交关闭。只要执行一个select语句，事务就启动且不会自动提交，直到主动commit或者rollback或者断开连接
- 建议使用第一种启动事务方式：如果考虑多一次begin交互过程，可以使用commit work and chain语法。在 autocommit = 1 时，用begin显式开启事务，如果执行commit则提交事务；如果执行commit work and chain 则提交事务并且自动启动下一个事务

##### 事务启动的时机

- begin/start transaction 命令不是一个事务的起点，在执行到它之后的第一个操作InnoDB表的语句时，事务才真正启动。它的一致性视图是在执行第一个快照读语句时创建的
- 使用start transaction with consistent snapshot 马上启动一个事务。它的一致性视图是在执行这条语句时创建的

##### 长事务

在该事务提交之前会记录大量的回滚日志，占用空间，占用锁，影响性能。

##### 避免长事务

- 开发端
  - 确认是否使用了set autocommit = 0 ，可以开启MySQL的general_log，随便跑一个业务逻辑，通过日志来确认，要做的就是把它改过来
  - 确认是否有不必要的只读事务
  - 业务连接数据库时根据业务本身的预估，设置 SET MAX_EXECUTION_TIME 命令来控制每个语句的最长时间，避免单个语句意外执行太长时间
- 数据库端
  - 监控 information_schema.Innodb_trx表，设置长事务阈值，超过就报警或者kill
  - 在业务功能测试时输出所有的general_log 分析日志行为提前发现问题



#### 索引

作用：提高数据查询效率

##### 常见的索引模型

- 哈希表
  - 通过key-value存储数据，发生hash冲突时通过链表法解决冲突
  - 做区间查询的速度很慢，因为key是无序的，需要全部搜索一遍得出结果
  - 适合于只有等值查询的场景
- 有序数组
  - 适合于等值查询和范围查询，一般用二分法可以在log(n)的复杂度内找到结果
  - 查询效率还行，但更新操作成本较大，所以只适合于静态存储引擎
- 搜索树
  - 常规的二叉搜索树效率最高，但不适合数据库存储，因为索引不止存在于内存中，还要写到磁盘上
  - 为了减少读取磁盘的次数，一般用N叉树

##### InnoDB索引模型

- 表根据主键顺序以索引的形式存放，称为**索引组织表**，具体使用的是**B+树**索引模型

- 每一个索引在InnoDB中对应一棵B+树

- 索引类型

- - **主键索引**：也称为聚簇索引，叶子节点存的是整行数据

  - **非主键索引**：也称为二级索引，叶子节点存的是主键的值

  - - 普通索引，key、index关键字
    - 唯一索引，unique关键字

  - 主键查询的方式直接找到的是该行数据，返回即可；非主键查询，也就是普通索引查询则需要先搜索该索引的索引树，找到对于的主键值，再去主键索引的索引树上查询该行数据，也称做**回表**

  - 所以在应用中尽量使用主键查询

- 索引维护

- - 如果主键索引丧失连续性，则每次更新索引时可能产生页分裂和页合并操作，会大大降低性能，所以尽量使用主键自增策略
  - 从存储空间的角度来看，如果使用的不是自增字段做主键，那么由于其他非主键索引的叶子节点维护的是主键索引的值，这个节点的大小由主键类型确定，有可能很大，占用大量空间，所以也尽量使用自增主键。主键长度越小，**普通索引的叶子节点也越小，普通索引占用的空间也越小**

#### 索引优化案例

执行 `select * from T where k between 3 and 5`，其中主键为ID，K是普通索引。

查询过程需要先在k索引树上分别查找3、4、5的叶节点，然后再回表去找整行数据。在通过二级索引查询数据时，返回的是叶子节点中的数据（往往是主键），然后再进行回表操作。

那么可以通过以下方式减少回表次数

##### **覆盖索引**

- Select ID from T where k between 3 and 5
- 这时候只需要查询ID的值，而ID的值又在k索引树上，所以不需要回表，这就是**覆盖索引**。
- 当有高频查询请求是根据某一索引查询指定数据时，可以通过添加联合索引的方式直接返回联合索引的字段或者主键，减少IO磁盘读取整行数据

##### **最左前缀原则**

- 如果为每一种查询都添加索引实现覆盖索引，或者在低频请求中创建覆盖索引，又会很浪费。所以在B+树中，可以利用索引的“最左前缀”来定位记录
- 比如在（name，age）的联合索引中，当查询条件是name相关时，由于最左前缀原则，会先找到第一个满足要求的数据，然后向后遍历直到不满足条件为止。所以当要根据name查询address时，就不必再单独设置（name，address）索引实现覆盖索引，根据最左前缀原则，查询先找到第一个满足name条件的节点，返回其主键，然后依次往后查询同一name下的其他节点数据

##### **联合索引**

- 根据创建联合索引的顺序，以最左原则进行where检索。
- 在（name，age）索引中，where      name或者where name and age都会用到索引，但where      age时不会用到索引。所以要根据业务需求，将频繁查询的数据进行靠左创建索引

##### **索引下推**

- like ‘hello%’ and      age>10，在5.6之前，会对匹配的每一条数据进行回表查询；在5.6之后，会先过滤掉 <      10 的数据，再进行回表查询。

##### 如何给字符串字段加索引？以email为例

两种选择

- 直接全字段索引，index(email)
- 前缀索引，index(email(6))

对于一条查询语句来说，如果是全字段索引，只需要进行一次回表；对于前缀索引来说，回表的次数由前缀的区分度决定，区分度高回表次数少，反之回表次数高。

使用前缀索引就会丧失覆盖索引的作用

##### 索引字段不能进行函数操作，但是索引字段的参数可以随便加函数



#### 锁

##### 分类

根据加锁范围可分为：全局锁、表级锁、行级锁

##### 全局锁

- 对整个数据库进行加锁

- MySQL提供全局读锁的方法：Flush tables with read lock（FTWRL）

- - 这个命令使得整个库处于只读的状态，其他语句一律阻塞

  - 使用场景：全库逻辑备份

  - 风险

  - - 如果在主库备份，在备份期间都不能执行更新，业务停摆
    - 如果在从库上备份，在备份期间从库不能执行从主库同步过来的binlog，导致主从延迟

- 官方自带逻辑备份工具 mysqldump，当mysqldump使用参数 --single-transaction 的时候，会启动一个事务，确保拿到一致性视图（类似于可重复读的原理），因为MVCC的支持，在这个过程中数据是可以正常更新的

- 上面的这个功能虽然好，但需要存储引擎的支持。

- 既然要全库只读，为什么不用 set global readonly = true ？

- - 在某个slave上如果用户有超级权限时，readonly不管用

  - 在有些系统中，readonly的值被用来做其他逻辑，比如判断主备库，所以修改该字段的风险太大

  - 异常处理机制有区别

  - - 执行FTWRL后如果由于client发生异常断开，MySQL会自动释放这个全局锁
    - 设置readonly后，client异常断开，数据库会一直保持readonly状态

##### 表级锁

- 有两种：表锁、元数据锁（meta data lock，MDL）

- 表锁

- - 语法：lock tables … read/write，lock tables t1 read, t2 write;
  - 可以用unlock tables 主动释放锁，也可以在client断开的时候自动释放
  - lock tables 除了限制别的线程的读写之外，也限制了本线程接下来的操作对象
  - InnoDB不使用lock tables控制并发，因为影响范围太大

- MDL锁

- - 锁的是表结构数据，也就是禁止DDL语句

  - 不需要显示使用，在访问每一个表时都会自动添加

  - 执行DML语句时添加MDL读锁，执行DDL语句时添加MDL写锁

  - 读锁之前不互斥，写锁之间、读写之间都互斥

  - MDL会直到事务提交才释放，在做表结构变更时，一定要小心

  - 如何安全的给小表加字段？

  - - 解决长事务，事务不提交，就会一直占用MDL锁
    - 在 alter table 语句中设定等待时间，拿不到就暂时放弃，之后在重试

  - Online DDL

  - - 拿MDL写锁
    - 降级成MDL读锁
    - 真正执行DDL
    - 升级成MDL写锁
    - 释放

##### 行锁（InnoDB支持）

- InnoDB行级锁是通过锁索引记录实现的，如果更新的列没有建立索引则会锁住整个表

- 两阶段锁

- - 在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是等到commmit之后才释放
  - 如果事务中需要锁多个行，要把可能造成锁冲突、最可能影响并发度的锁尽量往后放

- 死锁

- - 解决策略

  - - 直接进入等待直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置，但一般不建议对其进行更改，如果设置的小了就不容易分辨出到底是死锁还是其他事务确实会占用这个锁很久
    - 发起死锁检测：发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect设置为on。局限性是每个被堵住的线程都会进行死锁检测，会消耗大量的CPU资源

- **解决热点行数据更新导致的性能问题？**

- - 控制并发度，对相同的行的更新，在进入引擎之前排队（可能需要修改mysql源码），这样就不会有大量的死锁检测
  - 将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务逻辑会很复杂